{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/96592 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'maxh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a5394383f538>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m#print (img.size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mmax_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxh\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;31m#print (img.size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mmax_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxw\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'maxh' is not defined"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import os\n",
    "print(\"Started\")\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from tqdm import tqdm \n",
    "\n",
    "path = \"./data/train_set/\"\n",
    "\n",
    "max_width = 0\n",
    "max_height = 0\n",
    "\n",
    "for file in tqdm(os.listdir(path)):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        #print(os.path.join(, file))\n",
    "        filename = os.path.join(path,file)\n",
    "        img = Image.open(filename)\n",
    "        #print (img.size)\n",
    "        max_height = max(maxh , img.size[0])\n",
    "        #print (img.size)\n",
    "        max_width = max(maxw , img.size[1])\n",
    "        \n",
    "print(max_width, max_height)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: __main__.py [-h] [--dataset DATASET] [--epochs EPOCHS]\n",
      "                   [--start-epoch START_EPOCH] [-b BATCH_SIZE] [--lr LR]\n",
      "                   [--momentum MOMENTUM] [--nesterov NESTEROV]\n",
      "                   [--weight-decay WEIGHT_DECAY] [--print-freq PRINT_FREQ]\n",
      "                   [--layers LAYERS] [--widen-factor WIDEN_FACTOR]\n",
      "                   [--droprate DROPRATE] [--no-augment] [--resume RESUME]\n",
      "                   [--name NAME] [--tensorboard]\n",
      "__main__.py: error: unrecognized arguments: -f /run/user/2200/jupyter/kernel-e664ca81-6c51-4e37-a59f-a41735f7dc72.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import print_function, division\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "# import torch.utils.data\n",
    "# import torchvision.transforms as transforms\n",
    "# import torchvision.datasets as datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from wideresnet import WideResNet\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# used for logging to TensorBoard\n",
    "from tensorboard_logger import configure, log_value\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch WideResNet Training')\n",
    "parser.add_argument('--dataset', default='ifood', type=str,\n",
    "\t\t\t\t\thelp='dataset (ifood18[default] or cifar10 or cifar100)')\n",
    "parser.add_argument('--epochs', default=200, type=int,\n",
    "\t\t\t\t\thelp='number of total epochs to run')\n",
    "parser.add_argument('--start-epoch', default=0, type=int,\n",
    "\t\t\t\t\thelp='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('-b', '--batch-size', default=128, type=int,\n",
    "\t\t\t\t\thelp='mini-batch size (default: 128)')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.001, type=float,\n",
    "\t\t\t\t\thelp='initial learning rate')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, help='momentum')\n",
    "parser.add_argument('--nesterov', default=True, type=bool, help='nesterov momentum')\n",
    "parser.add_argument('--weight-decay', '--wd', default=5e-4, type=float,\n",
    "\t\t\t\t\thelp='weight decay (default: 5e-4)')\n",
    "parser.add_argument('--print-freq', '-p', default=10, type=int,\n",
    "\t\t\t\t\thelp='print frequency (default: 10)')\n",
    "parser.add_argument('--layers', default=28, type=int,\n",
    "\t\t\t\t\thelp='total number of layers (default: 28)')\n",
    "parser.add_argument('--widen-factor', default=4, type=int,\n",
    "\t\t\t\t\thelp='widen factor (default: 10)')\n",
    "parser.add_argument('--droprate', default=0.3, type=float,\n",
    "\t\t\t\t\thelp='dropout probability (default: 0.0)')\n",
    "parser.add_argument('--no-augment', dest='augment', action='store_false',\n",
    "\t\t\t\t\thelp='whether to use standard augmentation (default: True)')\n",
    "parser.add_argument('--resume', default='', type=str,\n",
    "\t\t\t\t\thelp='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('--name', default='WideResNet-ifood-28-10', type=str,\n",
    "\t\t\t\t\thelp='name of experiment')\n",
    "parser.add_argument('--tensorboard',\n",
    "\t\t\t\t\thelp='Log progress to TensorBoard', action='store_true')\n",
    "parser.set_defaults(augment=True)\n",
    "\n",
    "best_prec1 = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FoodDataset(Dataset):\n",
    "\t\"\"\"Food dataset.\"\"\"\n",
    "\tdef __init__(self, root_dir, csv_file, transform):\n",
    "\t\t\"\"\"\n",
    "\t\tArgs:\n",
    "\t\t\tcsv_file (string): Path to the csv file with annotations.\n",
    "\t\t\troot_dir (string): Directory with all the images.\n",
    "\t\t\ttransform (callable, optional): Optional transform to be applied\n",
    "\t\t\t\ton a sample.\n",
    "\t\t\"\"\"\n",
    "\t\tself.labels = pd.read_csv(csv_file)\n",
    "\t\tself.root_dir = root_dir\n",
    "\t\tself.transform = transform\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.labels)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\timg_name = os.path.join(self.root_dir,self.labels.iloc[idx, 0])\n",
    "\t\timage = Image.open(img_name)\n",
    "\t\tcorrect_label = self.labels.iloc[idx, 1]\n",
    "\t\t#correct_label = correct_label.astype('int')\n",
    "\t\tif self.transform:\n",
    "\t\t\timage = self.transform(image)\n",
    "\n",
    "\t\tsample = (image, correct_label)\n",
    "\n",
    "\t\treturn sample\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "\tglobal args, best_prec1\n",
    "\targs = parser.parse_args()\n",
    "\tif args.tensorboard: \n",
    "\t\tconfigure(\"runs/%s\"%(args.name))\n",
    "\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t\n",
    "\t# Data loading code\n",
    "\tnormalize = transforms.Normalize(mean=[x/255.0 for x in [125.3, 123.0, 113.9]],\n",
    "\t\t\t\t\t\t\t\t\t std=[x/255.0 for x in [63.0, 62.1, 66.7]])\n",
    "\n",
    "\tif args.augment:\n",
    "\t\ttransform_train = transforms.Compose([\n",
    "\t\t\ttransforms.Resize(256,256),\n",
    "\t\t\ttransforms.ToTensor(),\n",
    "\t\t\ttransforms.Lambda(lambda x: F.pad(\n",
    "\t\t\t\t\t\t\t\tVariable(x.unsqueeze(0), requires_grad=False, volatile=True),\n",
    "\t\t\t\t\t\t\t\t(4,4,4,4),mode='reflect').data.squeeze()),\n",
    "\t\t\ttransforms.ToPILImage(),\n",
    "\t\t\ttransforms.RandomCrop(32),\n",
    "\t\t\ttransforms.RandomHorizontalFlip(),\n",
    "\t\t\ttransforms.ToTensor(),\n",
    "\t\t\tnormalize,\n",
    "\t\t\t])\n",
    "\telse:\n",
    "\t\ttransform_train = transforms.Compose([\n",
    "\t\t\ttransforms.ToTensor(),\n",
    "\t\t\tnormalize,\n",
    "\t\t\t])\n",
    "\t\n",
    "\ttransform_test = transforms.Compose([\n",
    "\t\ttransforms.ToTensor(),\n",
    "\t\tnormalize\n",
    "\t\t])\n",
    "\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\tkwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "\t#assert(args.dataset == 'cifar10' or args.dataset == 'cifar100')\n",
    "\t\n",
    "\ttrain_data_path =\"/data/unagi0/food/train_set/\"\n",
    "\tval_data_path =\"/home/mil/gupta/ifood18/data/val_set/\"\n",
    "\t\n",
    "\ttrain_label =\"/home/mil/gupta/ifood18/data/labels/train_info.csv\"\n",
    "\tval_label =\"/home/mil/gupta/ifood18/data/labels/val_info.csv\"\n",
    "\t\n",
    "\t\n",
    "\t#transformations = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "\ttrain_dataset =  FoodDataset(train_data_path, train_label, transform= transform_train)\n",
    "\tval_dataset =  FoodDataset(val_data_path, val_label, transform= transform_train)\n",
    "\t\n",
    "\n",
    "\t\n",
    "\n",
    "\t#custom_mnist_from_csv = \\\n",
    "\t#    CustomDatasetFromCSV('../data/mnist_in_csv.csv',\n",
    "\t#                         28, 28,\n",
    "\t#                         transformations)\n",
    "\n",
    "\ttrain_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=116,shuffle=False)\n",
    "\n",
    "\tval_loader = torch.utils.data.DataLoader(dataset=val_dataset,batch_size=116,shuffle=False)\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "# \ttrain_labels = pd.read_csv('./data/labels/train_info.csv')\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "# \ttrain_loader = torch.utils.data.DataLoader(\n",
    "#         datasets.__dict__[args.dataset.upper()](train_data_path, train=True, download=True,\n",
    "#                          transform=transform_train),\n",
    "#         batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "#     val_loader = torch.utils.data.DataLoader(\n",
    "#         datasets.__dict__[args.dataset.upper()](val_data_path, train=False, transform=transform_test),\n",
    "#         batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\t# create model\n",
    "\tmodel = WideResNet(args.layers, 211, args.widen_factor, dropRate=args.droprate)\n",
    "\n",
    "\t# get the number of model parameters\n",
    "\tprint('Number of model parameters: {}'.format(\n",
    "\t\tsum([p.data.nelement() for p in model.parameters()])))\n",
    "\n",
    "\t# for training on multiple GPUs.\n",
    "\t# Use CUDA_VISIBLE_DEVICES=0,1 to specify which GPUs to use\n",
    "\t# model = torch.nn.DataParallel(model).cuda()\n",
    "\tmodel = model.cuda()\n",
    "\n",
    "\t# optionally resume from a checkpoint\n",
    "\tif args.resume:\n",
    "\t\tif os.path.isfile(args.resume):\n",
    "\t\t\tprint(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "\t\t\tcheckpoint = torch.load(args.resume)\n",
    "\t\t\targs.start_epoch = checkpoint['epoch']\n",
    "\t\t\tbest_prec1 = checkpoint['best_prec1']\n",
    "\t\t\tmodel.load_state_dict(checkpoint['state_dict'])\n",
    "\t\t\tprint(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "\t\t\t\t  .format(args.resume, checkpoint['epoch']))\n",
    "\t\telse:\n",
    "\t\t\tprint(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "\n",
    "\tcudnn.benchmark = True\n",
    "\n",
    "\t# define loss function (criterion) and optimizer\n",
    "\tcriterion = nn.CrossEntropyLoss().cuda()\n",
    "\toptimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "\t\t\t\t\t\t\t\tmomentum=args.momentum, nesterov = args.nesterov,\n",
    "\t\t\t\t\t\t\t\tweight_decay=args.weight_decay)\n",
    "\n",
    "\tfor epoch in range(args.start_epoch, args.epochs):\n",
    "\t\tadjust_learning_rate(optimizer, epoch+1)\n",
    "\n",
    "\t\t# train for one epoch\n",
    "\t\ttrain(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "\t\t# evaluate on validation set\n",
    "\t\tprec1 = validate(val_loader, model, criterion, epoch)\n",
    "\n",
    "\t\t# remember best prec@1 and save checkpoint\n",
    "\t\tis_best = prec1 > best_prec1\n",
    "\t\tbest_prec1 = max(prec1, best_prec1)\n",
    "\t\tsave_checkpoint({\n",
    "\t\t\t'epoch': epoch + 1,\n",
    "\t\t\t'state_dict': model.state_dict(),\n",
    "\t\t\t'best_prec1': best_prec1,\n",
    "\t\t}, is_best)\n",
    "\tprint ('Best accuracy: ', best_prec1)\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "\t\"\"\"Train for one epoch on the training set\"\"\"\n",
    "\tbatch_time = AverageMeter()\n",
    "\tlosses = AverageMeter()\n",
    "\ttop1 = AverageMeter()\n",
    "\n",
    "\t# switch to train mode\n",
    "\tmodel.train()\n",
    "\n",
    "\tend = time.time()\n",
    "\t#print(train_loader)\n",
    "\t#print(size(train_loader))\n",
    "\tfor i, (inp, target) in enumerate(train_loader):\n",
    "\t\t\n",
    "\t\ttarget = target.cuda(async=True)\n",
    "\t\tinp = inp.cuda()\n",
    "\t\t\n",
    "\t\tinput_var = torch.autograd.Variable(inp)\n",
    "\t\ttarget_var = torch.autograd.Variable(target)\n",
    "\n",
    "\n",
    "\t\t# compute output\n",
    "\t\toutput = model(input_var)\n",
    "\t\tloss = criterion(output, target_var)\n",
    "\n",
    "\t\t# measure accuracy and record loss\n",
    "\t\tprec1 = accuracy(output.data, target, topk=(1,))[0]\n",
    "\t\tlosses.update(loss.data[0], inp.size(0))\n",
    "\t\ttop1.update(prec1[0], inp.size(0))\n",
    "\n",
    "\t\t# compute gradient and do SGD step\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\t# measure elapsed time\n",
    "\t\tbatch_time.update(time.time() - end)\n",
    "\t\tend = time.time()\n",
    "\n",
    "\t\tif i % args.print_freq == 0:\n",
    "\t\t\tprint('Epoch: [{0}][{1}/{2}]\\t'\n",
    "\t\t\t\t  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "\t\t\t\t  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "\t\t\t\t  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "\t\t\t\t\t  epoch, i, len(train_loader), batch_time=batch_time,\n",
    "\t\t\t\t\t  loss=losses, top1=top1))\n",
    "\t# log to TensorBoard\n",
    "\tif args.tensorboard:\n",
    "\t\tlog_value('train_loss', losses.avg, epoch)\n",
    "\t\tlog_value('train_acc', top1.avg, epoch)\n",
    "\n",
    "def validate(val_loader, model, criterion, epoch):\n",
    "\t\"\"\"Perform validation on the validation set\"\"\"\n",
    "\tbatch_time = AverageMeter()\n",
    "\tlosses = AverageMeter()\n",
    "\ttop1 = AverageMeter()\n",
    "\n",
    "\t# switch to evaluate mode\n",
    "\tmodel.eval()\n",
    "\n",
    "\tend = time.time()\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\tfor i, (input, target) in enumerate(val_loader):\n",
    "\t\ttarget = target.cuda(async=True)\n",
    "\t\tinput = input.cuda()\n",
    "\t\tinput_var = torch.autograd.Variable(input, volatile=True)\n",
    "\t\ttarget_var = torch.autograd.Variable(target, volatile=True)\n",
    "\n",
    "\t\t# compute output\n",
    "\t\toutput = model(input_var)\n",
    "\t\tloss = criterion(output, target_var)\n",
    "\n",
    "\t\t# measure accuracy and record loss\n",
    "\t\tprec1 = accuracy(output.data, target, topk=(1,))[0]\n",
    "\t\tlosses.update(loss.data[0], input.size(0))\n",
    "\t\ttop1.update(prec1[0], input.size(0))\n",
    "\n",
    "\t\t# measure elapsed time\n",
    "\t\tbatch_time.update(time.time() - end)\n",
    "\t\tend = time.time()\n",
    "\n",
    "\t\tif i % args.print_freq == 0:\n",
    "\t\t\tprint('Test: [{0}/{1}]\\t'\n",
    "\t\t\t\t  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "\t\t\t\t  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "\t\t\t\t  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "\t\t\t\t\t  i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "\t\t\t\t\t  top1=top1))\n",
    "\n",
    "\tprint(' * Prec@1 {top1.avg:.3f}'.format(top1=top1))\n",
    "\t# log to TensorBoard\n",
    "\tif args.tensorboard:\n",
    "\t\tlog_value('val_loss', losses.avg, epoch)\n",
    "\t\tlog_value('val_acc', top1.avg, epoch)\n",
    "\treturn top1.avg\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "\t\"\"\"Saves checkpoint to disk\"\"\"\n",
    "\tdirectory = \"runs/%s/\"%(args.name)\n",
    "\tif not os.path.exists(directory):\n",
    "\t\tos.makedirs(directory)\n",
    "\tfilename = directory + filename\n",
    "\ttorch.save(state, filename)\n",
    "\tif is_best:\n",
    "\t\tshutil.copyfile(filename, 'runs/%s/'%(args.name) + 'model_best.pth.tar')\n",
    "\n",
    "class AverageMeter(object):\n",
    "\t\"\"\"Computes and stores the average and current value\"\"\"\n",
    "\tdef __init__(self):\n",
    "\t\tself.reset()\n",
    "\n",
    "\tdef reset(self):\n",
    "\t\tself.val = 0\n",
    "\t\tself.avg = 0\n",
    "\t\tself.sum = 0\n",
    "\t\tself.count = 0\n",
    "\n",
    "\tdef update(self, val, n=1):\n",
    "\t\tself.val = val\n",
    "\t\tself.sum += val * n\n",
    "\t\tself.count += n\n",
    "\t\tself.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "\t\"\"\"Sets the learning rate to the initial LR divided by 5 at 60th, 120th and 160th epochs\"\"\"\n",
    "\tlr = args.lr * ((0.2 ** int(epoch >= 60)) * (0.2 ** int(epoch >= 120))* (0.2 ** int(epoch >= 160)))\n",
    "\t# log to TensorBoard\n",
    "\tif args.tensorboard:\n",
    "\t\tlog_value('learning_rate', lr, epoch)\n",
    "\tfor param_group in optimizer.param_groups:\n",
    "\t\tparam_group['lr'] = lr\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "\t\"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "\tmaxk = max(topk)\n",
    "\tbatch_size = target.size(0)\n",
    "\n",
    "\t_, pred = output.topk(maxk, 1, True, True)\n",
    "\tpred = pred.t()\n",
    "\tcorrect = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "\tres = []\n",
    "\tfor k in topk:\n",
    "\t\tcorrect_k = correct[:k].view(-1).float().sum(0)\n",
    "\t\tres.append(correct_k.mul_(100.0 / batch_size))\n",
    "\treturn res\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tmain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "list_a = [np.arange(5)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_a=np.arange(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_a[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_a[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
